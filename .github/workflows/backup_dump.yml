name: Supabase Backup Every 6 Minutes

on:
  schedule:
    - cron: '*/6 * * * *'  # every 6 minutes
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-22.04
    steps:
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client gzip python3-pip
          pip3 install --upgrade awscli

      - name: Dump Supabase DB
        env:
          DB_URL: ${{ secrets.DB_POOLER_URL }}
        run: |
          DATE=$(date +%F-%H%M%S)   # add seconds to avoid collisions
          echo "Dumping DB..."
          pg_dump "$DB_URL" --no-owner --no-acl | gzip > dump_$DATE.sql.gz

      - name: Upload dump to S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: "eu-north-1"
        run: |
          DATE=$(date +%F-%H%M%S)
          echo "Uploading dump to S3..."
          aws s3 cp dump_$DATE.sql.gz s3://jamspots-pg-dump/backups/

      - name: Cleanup local dump
        run: rm dump_*.sql.gz

      - name: Remove old backups from S3 (keep 30 latest)
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: "eu-north-1"
        run: |
          echo "Deleting old backups..."
          aws s3 ls s3://jamspots-pg-dump/backups/ \
            | awk '{print $4}' \
            | grep '^dump_' \
            | sort \
            | head -n -30 \
            | while read f; do
                [ -n "$f" ] && aws s3 rm s3://jamspots-pg-dump/backups/$f
              done
